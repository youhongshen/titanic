{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'read_and_process_data.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8412921348314607"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf.fit(X, y)\n",
    "train_yhat = clf.predict(X)\n",
    "accuracy_score(y, train_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78770949720670391"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_yhat = clf.predict(dev_X)\n",
    "accuracy_score(dev_y, dev_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0, 'max_depth': 6, 'n_estimators': 200}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 2),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 300, 50),\n",
    "    'gamma': hp.quniform('gamma', 0, 5, 1),\n",
    "#     'subsample': hp.uniform('subsample', 0.5, 1, 0.1),\n",
    "#     'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1, 0.1),\n",
    "#     'learning_rate': hp.loguniform('learning_rate', 0.01, 0.2),\n",
    "}\n",
    "\n",
    "# reg_lambda - L2 regularization\n",
    "\n",
    "def score(params):\n",
    "    # convert all the numbers to integer\n",
    "    print(params)\n",
    "    params = {x: int(y) for x, y in params.iteritems()}\n",
    "    params['n_jobs'] = -1\n",
    "    clf = XGBClassifier(**params)\n",
    "    return {'loss': 1-check_accuracy(clf, X, y, dev_X, dev_y), 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "# best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=200)\n",
    "best = {'gamma': 0.0, 'max_depth': 6.0, 'n_estimators': 200.0}\n",
    "best = {x: int(y) for x, y in best.iteritems()}\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595505617977528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tuned = XGBClassifier(**best)\n",
    "clf_tuned = clf_tuned.fit(X, y)\n",
    "train_p = clf_tuned.predict(X)\n",
    "accuracy_score(y, train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83798882681564246"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_p = clf_tuned.predict(dev_X)\n",
    "accuracy_score(dev_y, dev_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf_tuned.predict(test_X)\n",
    "\n",
    "outfile = os.path.join(data_dir, 'prediction.csv')\n",
    "df = pd.DataFrame()\n",
    "df['PassengerId'] = passenger_id\n",
    "df['Survived'] = pred\n",
    "df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
